{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpeza dos dados de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tweets_train=train_df['text']\n",
    "sample_tweets_test=test_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpeza(tweets):\n",
    "    tweets = tweets.str.replace(r'@[a-zA-Z0-9_!.]{0,25}','')\n",
    "    tweets = tweets.str.replace('(http|ftp|https)://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+/(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+','')\n",
    "    tweets = tweets.str.replace(r'[0-9]','')\n",
    "    tweets = tweets.replace(\"\\\\x89Û_\",'')\n",
    "    tweets = tweets.replace('\\x89ÛÓ','')\n",
    "    tweets = tweets.replace('\\x89ÛÓ','')\n",
    "    tweets = tweets.replace('\\x89ÛÒ','')\n",
    "    tweets = tweets.replace('\\x89Û','')\n",
    "    tweets = tweets.replace('\\x89Û÷','')\n",
    "    tweets = tweets.replace('\\x89ûï','')\n",
    "    #retirada de símbolos não alfanuméticos \n",
    "    tweets = tweets.str.replace(r\"[#,.;:_?!()\\[\\]]\",\"\")\n",
    "    tweets = tweets.str.lower()\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yfrom\\AppData\\Local\\Temp\\ipykernel_12048\\1236119256.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweets = tweets.str.replace(r'@[a-zA-Z0-9_!.]{0,25}','')\n",
      "C:\\Users\\yfrom\\AppData\\Local\\Temp\\ipykernel_12048\\1236119256.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweets = tweets.str.replace('(http|ftp|https)://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+/(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+','')\n",
      "C:\\Users\\yfrom\\AppData\\Local\\Temp\\ipykernel_12048\\1236119256.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweets = tweets.str.replace(r'[0-9]','')\n",
      "C:\\Users\\yfrom\\AppData\\Local\\Temp\\ipykernel_12048\\1236119256.py:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweets = tweets.str.replace(r\"[#,.;:_?!()\\[\\]]\",\"\")\n"
     ]
    }
   ],
   "source": [
    "sample_tweets_train = limpeza(sample_tweets_train)\n",
    "sample_tweets_test = limpeza(sample_tweets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "def lematizar(tweets):\n",
    "    sample_tweets= []\n",
    "    for tweet in tweets:\n",
    "        filtered_list = []\n",
    "        words_lemmatized = []\n",
    "        words = []\n",
    "        words = word_tokenize(tweet) \n",
    "        words_lemmatized = [lemmatizer.lemmatize(word) for word in words] \n",
    "        for word in words_lemmatized:\n",
    "            if word not in stop_words:\n",
    "                filtered_list.append(word)\n",
    "        sample_tweets.append(filtered_list)\n",
    "    return sample_tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tweets_train = lematizar(sample_tweets_train)\n",
    "sample_tweets_test = lematizar(sample_tweets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['words']= sample_tweets_train\n",
    "test_df['words']= sample_tweets_test\n",
    "test_df = test_df.drop(columns=['location', 'keyword','id','text'])\n",
    "train_df = train_df.drop(columns=['location', 'keyword','id','text'])\n",
    "train_df['text'] = train_df['words'].apply(lambda x: ' '.join([str(elem) for elem in x]))\n",
    "test_df['text'] = test_df['words'].apply(lambda x: ' '.join([str(elem) for elem in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>words</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[deed, reason, earthquake, may, allah, forgive...</td>\n",
       "      <td>deed reason earthquake may allah forgive u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[resident, asked, 'shelter, place, ', notified...</td>\n",
       "      <td>resident asked 'shelter place ' notified offic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[people, receive, wildfire, evacuation, order,...</td>\n",
       "      <td>people receive wildfire evacuation order calif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[got, sent, photo, ruby, alaska, smoke, wildfi...</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfire pour...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                              words  \\\n",
       "0       1  [deed, reason, earthquake, may, allah, forgive...   \n",
       "1       1      [forest, fire, near, la, ronge, sask, canada]   \n",
       "2       1  [resident, asked, 'shelter, place, ', notified...   \n",
       "3       1  [people, receive, wildfire, evacuation, order,...   \n",
       "4       1  [got, sent, photo, ruby, alaska, smoke, wildfi...   \n",
       "\n",
       "                                                text  \n",
       "0         deed reason earthquake may allah forgive u  \n",
       "1              forest fire near la ronge sask canada  \n",
       "2  resident asked 'shelter place ' notified offic...  \n",
       "3  people receive wildfire evacuation order calif...  \n",
       "4  got sent photo ruby alaska smoke wildfire pour...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[happened, terrible, car, crash]</td>\n",
       "      <td>happened terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[heard, earthquake, different, city, stay, saf...</td>\n",
       "      <td>heard earthquake different city stay safe ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[forest, fire, spot, pond, goose, fleeing, acr...</td>\n",
       "      <td>forest fire spot pond goose fleeing across str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[apocalypse, lighting, spokane, wildfire]</td>\n",
       "      <td>apocalypse lighting spokane wildfire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[typhoon, soudelor, kill, china, taiwan]</td>\n",
       "      <td>typhoon soudelor kill china taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               words  \\\n",
       "0                   [happened, terrible, car, crash]   \n",
       "1  [heard, earthquake, different, city, stay, saf...   \n",
       "2  [forest, fire, spot, pond, goose, fleeing, acr...   \n",
       "3          [apocalypse, lighting, spokane, wildfire]   \n",
       "4           [typhoon, soudelor, kill, china, taiwan]   \n",
       "\n",
       "                                                text  \n",
       "0                        happened terrible car crash  \n",
       "1  heard earthquake different city stay safe ever...  \n",
       "2  forest fire spot pond goose fleeing across str...  \n",
       "3               apocalypse lighting spokane wildfire  \n",
       "4                 typhoon soudelor kill china taiwan  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "count_treino_tfidf = tfidf_vectorizer.fit_transform(train_df['text'])\n",
    "count_teste_tfidf = tfidf_vectorizer.transform(test_df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tfidf = LogisticRegression(C=1, class_weight='dict', solver='newton-cg',multi_class='auto', n_jobs=-1, random_state=40,max_iter= 1000)\n",
    "clf_tfidf.fit(count_treino_tfidf, train_df['target'])\n",
    "sample_submission['target'] = clf_tfidf.predict(count_teste_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97df6f2fb7f9c55379e2d2444043f8d5f157c223a696fe5032f4316ff3fcd6e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
