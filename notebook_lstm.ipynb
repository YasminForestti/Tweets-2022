{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpeza dos dados de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tweets_train=train_df['text']\n",
    "sample_tweets_test=test_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpeza(tweets):\n",
    "    tweets = tweets.str.replace(r'@[a-zA-Z0-9_!.]{0,25}','')\n",
    "    tweets = tweets.str.replace('(http|ftp|https)://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+/(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+','')\n",
    "    tweets = tweets.str.replace(r'[0-9]','')\n",
    "    tweets = tweets.replace(\"\\\\x89Û_\",'')\n",
    "    tweets = tweets.replace('\\x89ÛÓ','')\n",
    "    tweets = tweets.replace('\\x89ÛÓ','')\n",
    "    tweets = tweets.replace('\\x89ÛÒ','')\n",
    "    tweets = tweets.replace('\\x89Û','')\n",
    "    tweets = tweets.replace('\\x89Û÷','')\n",
    "    tweets = tweets.replace('\\x89ûï','')\n",
    "    #retirada de símbolos não alfanuméticos \n",
    "    tweets = tweets.str.replace(r\"[#,.;:_?!()\\[\\]]\",\"\")\n",
    "    tweets = tweets.str.lower()\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yfrom\\AppData\\Local\\Temp\\ipykernel_14808\\1236119256.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweets = tweets.str.replace(r'@[a-zA-Z0-9_!.]{0,25}','')\n",
      "C:\\Users\\yfrom\\AppData\\Local\\Temp\\ipykernel_14808\\1236119256.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweets = tweets.str.replace('(http|ftp|https)://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+/(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+','')\n",
      "C:\\Users\\yfrom\\AppData\\Local\\Temp\\ipykernel_14808\\1236119256.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweets = tweets.str.replace(r'[0-9]','')\n",
      "C:\\Users\\yfrom\\AppData\\Local\\Temp\\ipykernel_14808\\1236119256.py:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweets = tweets.str.replace(r\"[#,.;:_?!()\\[\\]]\",\"\")\n"
     ]
    }
   ],
   "source": [
    "sample_tweets_train = limpeza(sample_tweets_train)\n",
    "sample_tweets_test = limpeza(sample_tweets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "def lematizar(tweets):\n",
    "    sample_tweets= []\n",
    "    for tweet in tweets:\n",
    "        filtered_list = []\n",
    "        words_lemmatized = []\n",
    "        words = []\n",
    "        words = word_tokenize(tweet) \n",
    "        words_lemmatized = [lemmatizer.lemmatize(word) for word in words] \n",
    "        for word in words_lemmatized:\n",
    "            if word not in stop_words:\n",
    "                filtered_list.append(word)\n",
    "        sample_tweets.append(filtered_list)\n",
    "    return sample_tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tweets_train = lematizar(sample_tweets_train)\n",
    "sample_tweets_test = lematizar(sample_tweets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['words']= sample_tweets_train\n",
    "test_df['words']= sample_tweets_test\n",
    "test_df = test_df.drop(columns=['location', 'keyword','id','text'])\n",
    "train_df = train_df.drop(columns=['location', 'keyword','id','text'])\n",
    "train_df['text'] = train_df['words'].apply(lambda x: ' '.join([str(elem) for elem in x]))\n",
    "test_df['text'] = test_df['words'].apply(lambda x: ' '.join([str(elem) for elem in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>words</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[deed, reason, earthquake, may, allah, forgive...</td>\n",
       "      <td>deed reason earthquake may allah forgive u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[resident, asked, 'shelter, place, ', notified...</td>\n",
       "      <td>resident asked 'shelter place ' notified offic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[people, receive, wildfire, evacuation, order,...</td>\n",
       "      <td>people receive wildfire evacuation order calif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[got, sent, photo, ruby, alaska, smoke, wildfi...</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfire pour...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                              words  \\\n",
       "0       1  [deed, reason, earthquake, may, allah, forgive...   \n",
       "1       1      [forest, fire, near, la, ronge, sask, canada]   \n",
       "2       1  [resident, asked, 'shelter, place, ', notified...   \n",
       "3       1  [people, receive, wildfire, evacuation, order,...   \n",
       "4       1  [got, sent, photo, ruby, alaska, smoke, wildfi...   \n",
       "\n",
       "                                                text  \n",
       "0         deed reason earthquake may allah forgive u  \n",
       "1              forest fire near la ronge sask canada  \n",
       "2  resident asked 'shelter place ' notified offic...  \n",
       "3  people receive wildfire evacuation order calif...  \n",
       "4  got sent photo ruby alaska smoke wildfire pour...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[happened, terrible, car, crash]</td>\n",
       "      <td>happened terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[heard, earthquake, different, city, stay, saf...</td>\n",
       "      <td>heard earthquake different city stay safe ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[forest, fire, spot, pond, goose, fleeing, acr...</td>\n",
       "      <td>forest fire spot pond goose fleeing across str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[apocalypse, lighting, spokane, wildfire]</td>\n",
       "      <td>apocalypse lighting spokane wildfire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[typhoon, soudelor, kill, china, taiwan]</td>\n",
       "      <td>typhoon soudelor kill china taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               words  \\\n",
       "0                   [happened, terrible, car, crash]   \n",
       "1  [heard, earthquake, different, city, stay, saf...   \n",
       "2  [forest, fire, spot, pond, goose, fleeing, acr...   \n",
       "3          [apocalypse, lighting, spokane, wildfire]   \n",
       "4           [typhoon, soudelor, kill, china, taiwan]   \n",
       "\n",
       "                                                text  \n",
       "0                        happened terrible car crash  \n",
       "1  heard earthquake different city stay safe ever...  \n",
       "2  forest fire spot pond goose fleeing across str...  \n",
       "3               apocalypse lighting spokane wildfire  \n",
       "4                 typhoon soudelor kill china taiwan  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizar: Pad_sequence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "count_treino_tfidf = tfidf_vectorizer.fit_transform(train_df['text'])\n",
    "count_teste_tfidf = tfidf_vectorizer.transform(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features=5000\n",
    "tokenizer_train=Tokenizer(num_words=max_features,split=' ')\n",
    "tokenizer_test=Tokenizer(num_words=max_features,split=' ')\n",
    "tokenizer_train.fit_on_texts(train_df['text'])\n",
    "tokenizer_test.fit_on_texts(test_df['text'])\n",
    "X = tokenizer_train.texts_to_sequences(train_df['text'])\n",
    "X_test = tokenizer_test.texts_to_sequences(test_df['text'])\n",
    "X_test = pad_sequences(X_test)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 22)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state =41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 22, 100)           500000    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 22, 100)           0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 22, 100)           80400     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 22, 100)           0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 660,901\n",
      "Trainable params: 660,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 100\n",
    "lstm_out = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_dim,input_length = X.shape[1]))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, return_sequences=True,recurrent_dropout=0.4))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(lstm_out,dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "adam = optimizers.Adam(learning_rate=2e-3)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer=adam ,metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "191/191 [==============================] - 28s 104ms/step - loss: 0.5242 - accuracy: 0.7433 - val_loss: 0.4663 - val_accuracy: 0.7905\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 19s 100ms/step - loss: 0.3566 - accuracy: 0.8529 - val_loss: 0.4914 - val_accuracy: 0.7689\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 19s 101ms/step - loss: 0.2879 - accuracy: 0.8893 - val_loss: 0.5679 - val_accuracy: 0.7630\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 19s 100ms/step - loss: 0.2309 - accuracy: 0.9085 - val_loss: 0.6080 - val_accuracy: 0.7485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x165857f21c0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y, epochs = 10,validation_split = 0.2 ,callbacks=[es_callback], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 1s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test).round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 3s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy = round(metrics.accuracy_score(y_train,model.predict(X_train).round())*100)\n",
    "train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  is  :  0.9093893630991464\n",
      "Recall  is    :  0.8628048780487805\n",
      "Precision  is :  0.9218241042345277\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy  is  : ', (metrics.accuracy_score(y_test, y_pred)))\n",
    "print('Recall  is    : ', (metrics.recall_score(y_test, y_pred)))\n",
    "print('Precision  is : ', (metrics.precision_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submissão "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que eu tenho um modelo funcional de LSTM, tenho que modificar e entender melhor algumas coisas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entender:\n",
    "- Como achar o tamanho certo de cada vetor de entrada e saída.\n",
    "- Como saber o tamanho do vetor\n",
    "- Como saber a quantidade ideal de camadas de LSTM\n",
    "- Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coisas para o Vinicios explicar:\n",
    "- Optimizers\n",
    "- Camadas de uma rede neural (Dropout, Dense, input, output, camada oculta)\n",
    "- Treinamento\n",
    "- Gradiente..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97df6f2fb7f9c55379e2d2444043f8d5f157c223a696fe5032f4316ff3fcd6e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
