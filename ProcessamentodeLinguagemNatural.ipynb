{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bibliografia:\n",
    "\n",
    "Para o modelo de submissão:\n",
    "https://www.kaggle.com/code/philculliton/nlp-getting-started-tutorial/notebook\n",
    "\n",
    "Conceitos de ML:\n",
    "https://tatianaesc.medium.com/machine-learning-conceitos-e-modelos-f0373bf4f445\n",
    "\n",
    "Visualização:\n",
    "https://realpython.com/twitter-sentiment-python-docker-elasticsearch-kibana/\n",
    "\n",
    "Conceito VADER:\n",
    "https://ojs.aaai.org/index.php/ICWSM/article/view/14550/14399"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algoritmo de classificação utilizado no titanic\n",
    "wording bading / baggle of words/ df-tf (atribui pesos as palvras)\n",
    "feater extraction -> transformar o texto em uma coluna de banco de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)Limpeza das palavras: tirar as stop words, lematização, Bag-of-words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Vizualização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = train_df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Minimização dos ruídos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substituindo os espaços e lemmatizando as palavras chaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtro = train_df['tweets_lemmatizedword'].notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df_nonull=train_df[filtro]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7552"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_df_nonull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_lemmatizedword = sample_df_nonull['tweets_lemmatizedword']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_lemmatizedwords = [x.replace('%20', ' ') for x in tweets_lemmatizedword]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_lemmatizedwords_words = [word_tokenize(x) for x in tweets_lemmatizedwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_lemmatized= []\n",
    "for tweets_lemmatizedwords in tweets_lemmatizedwords_words:\n",
    "    words_lemmatized = []\n",
    "    for word in tweets_lemmatizedwords:\n",
    "        words_lemmatized.append(lemmatizer.lemmatize(word))\n",
    "    tweets_lemmatized.append(words_lemmatized)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yfrom\\AppData\\Local\\Temp\\ipykernel_11348\\2651402788.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample_df_nonull['keyword'] = key\n"
     ]
    }
   ],
   "source": [
    "sample_df_nonull['tweets_lemmatizedword'] = tweets_lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=train_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yfrom\\AppData\\Local\\Temp\\ipykernel_11348\\100282221.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweets = tweets.str.replace('(http|ftp|https)://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+/(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+','')\n"
     ]
    }
   ],
   "source": [
    "#Retirada dos links\n",
    "tweets = tweets.str.replace('(http|ftp|https)://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+/(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yfrom\\AppData\\Local\\Temp\\ipykernel_11348\\2578260738.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweets = tweets.str.replace(r'@[a-zA-Z0-9_!.]{0,25}','')\n"
     ]
    }
   ],
   "source": [
    "#Retirada dos @\n",
    "tweets = tweets.str.replace(r'@[a-zA-Z0-9_!.]{0,25}','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yfrom\\AppData\\Local\\Temp\\ipykernel_11348\\132602010.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweets = tweets.str.replace(r\"[#,.;:?!()\\[\\]]\",\"\")\n"
     ]
    }
   ],
   "source": [
    "#retirada de símbolos não alfanuméticos \n",
    "tweets = tweets.str.replace(r\"[#,.;:?!()\\[\\]]\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retirada de \\\\x89Û_ \\x89ÛÒ \\x89Û \\x89Û÷....(Não sei o que significa..e tem vários desse tipo)\n",
    "tweets = tweets.replace(\"\\\\x89Û_\",'')\n",
    "tweets = tweets.replace('\\x89ÛÓ','')\n",
    "tweets = tweets.replace('\\x89ÛÓ','')\n",
    "tweets = tweets.replace('\\x89ÛÒ','')\n",
    "tweets = tweets.replace('\\x89Û','')\n",
    "tweets = tweets.replace('\\x89Û÷','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yfrom\\AppData\\Local\\Temp\\ipykernel_11348\\2767507254.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweets = tweets.str.replace(r'[0-9]','')\n"
     ]
    }
   ],
   "source": [
    "tweets = tweets.str.replace(r'[0-9]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tweets= []\n",
    "for tweet in tweets:\n",
    "    filtered_list = []\n",
    "    words_lemmatized = []\n",
    "    words = []\n",
    "    words = word_tokenize(tweet) \n",
    "    words_lemmatized = [lemmatizer.lemmatize(word) for word in words] \n",
    "    for word in words_lemmatized:\n",
    "        #print(word)\n",
    "        if word not in stop_words:\n",
    "            filtered_list.append(word)\n",
    "    sample_tweets.append(filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['deed', 'reason', 'earthquake', 'may', 'allah', 'forgive', 'u'],\n",
       " ['forest', 'fire', 'near', 'la', 'ronge', 'sask', 'canada']]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tweets[0:2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97df6f2fb7f9c55379e2d2444043f8d5f157c223a696fe5032f4316ff3fcd6e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
