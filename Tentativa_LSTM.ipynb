{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpeza dos dados de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tweets_train=train_df['text']\n",
    "sample_tweets_test=test_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpeza(tweets):\n",
    "    tweets = tweets.str.replace(r'@[a-zA-Z0-9_!.]{0,25}','')\n",
    "    tweets = tweets.str.replace('(http|ftp|https)://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+/(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+','')\n",
    "    tweets = tweets.str.replace(r'[0-9]','')\n",
    "    tweets = tweets.replace(\"\\\\x89Û_\",'')\n",
    "    tweets = tweets.replace('\\x89ÛÓ','')\n",
    "    tweets = tweets.replace('\\x89ÛÓ','')\n",
    "    tweets = tweets.replace('\\x89ÛÒ','')\n",
    "    tweets = tweets.replace('\\x89Û','')\n",
    "    tweets = tweets.replace('\\x89Û÷','')\n",
    "    tweets = tweets.replace('\\x89ûï','')\n",
    "    #retirada de símbolos não alfanuméticos \n",
    "    tweets = tweets.str.replace(r\"[#,.;:_?!()\\[\\]]\",\"\")\n",
    "    tweets = tweets.str.lower()\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yfrom\\AppData\\Local\\Temp\\ipykernel_10664\\1236119256.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweets = tweets.str.replace(r'@[a-zA-Z0-9_!.]{0,25}','')\n",
      "C:\\Users\\yfrom\\AppData\\Local\\Temp\\ipykernel_10664\\1236119256.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweets = tweets.str.replace('(http|ftp|https)://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+/(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+','')\n",
      "C:\\Users\\yfrom\\AppData\\Local\\Temp\\ipykernel_10664\\1236119256.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweets = tweets.str.replace(r'[0-9]','')\n",
      "C:\\Users\\yfrom\\AppData\\Local\\Temp\\ipykernel_10664\\1236119256.py:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tweets = tweets.str.replace(r\"[#,.;:_?!()\\[\\]]\",\"\")\n"
     ]
    }
   ],
   "source": [
    "sample_tweets_train = limpeza(sample_tweets_train)\n",
    "sample_tweets_test = limpeza(sample_tweets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "def lematizar(tweets):\n",
    "    sample_tweets= []\n",
    "    for tweet in tweets:\n",
    "        filtered_list = []\n",
    "        words_lemmatized = []\n",
    "        words = []\n",
    "        words = word_tokenize(tweet) \n",
    "        words_lemmatized = [lemmatizer.lemmatize(word) for word in words] \n",
    "        for word in words_lemmatized:\n",
    "            if word not in stop_words:\n",
    "                filtered_list.append(word)\n",
    "        sample_tweets.append(filtered_list)\n",
    "    return sample_tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tweets_train = lematizar(sample_tweets_train)\n",
    "sample_tweets_test = lematizar(sample_tweets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['words']= sample_tweets_train\n",
    "test_df['words']= sample_tweets_test\n",
    "test_df = test_df.drop(columns=['location', 'keyword','id','text'])\n",
    "train_df = train_df.drop(columns=['location', 'keyword','id','text'])\n",
    "train_df['text'] = train_df['words'].apply(lambda x: ' '.join([str(elem) for elem in x]))\n",
    "test_df['text'] = test_df['words'].apply(lambda x: ' '.join([str(elem) for elem in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>words</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[deed, reason, earthquake, may, allah, forgive...</td>\n",
       "      <td>deed reason earthquake may allah forgive u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[resident, asked, 'shelter, place, ', notified...</td>\n",
       "      <td>resident asked 'shelter place ' notified offic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[people, receive, wildfire, evacuation, order,...</td>\n",
       "      <td>people receive wildfire evacuation order calif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[got, sent, photo, ruby, alaska, smoke, wildfi...</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfire pour...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                              words  \\\n",
       "0       1  [deed, reason, earthquake, may, allah, forgive...   \n",
       "1       1      [forest, fire, near, la, ronge, sask, canada]   \n",
       "2       1  [resident, asked, 'shelter, place, ', notified...   \n",
       "3       1  [people, receive, wildfire, evacuation, order,...   \n",
       "4       1  [got, sent, photo, ruby, alaska, smoke, wildfi...   \n",
       "\n",
       "                                                text  \n",
       "0         deed reason earthquake may allah forgive u  \n",
       "1              forest fire near la ronge sask canada  \n",
       "2  resident asked 'shelter place ' notified offic...  \n",
       "3  people receive wildfire evacuation order calif...  \n",
       "4  got sent photo ruby alaska smoke wildfire pour...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[happened, terrible, car, crash]</td>\n",
       "      <td>happened terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[heard, earthquake, different, city, stay, saf...</td>\n",
       "      <td>heard earthquake different city stay safe ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[forest, fire, spot, pond, goose, fleeing, acr...</td>\n",
       "      <td>forest fire spot pond goose fleeing across str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[apocalypse, lighting, spokane, wildfire]</td>\n",
       "      <td>apocalypse lighting spokane wildfire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[typhoon, soudelor, kill, china, taiwan]</td>\n",
       "      <td>typhoon soudelor kill china taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               words  \\\n",
       "0                   [happened, terrible, car, crash]   \n",
       "1  [heard, earthquake, different, city, stay, saf...   \n",
       "2  [forest, fire, spot, pond, goose, fleeing, acr...   \n",
       "3          [apocalypse, lighting, spokane, wildfire]   \n",
       "4           [typhoon, soudelor, kill, china, taiwan]   \n",
       "\n",
       "                                                text  \n",
       "0                        happened terrible car crash  \n",
       "1  heard earthquake different city stay safe ever...  \n",
       "2  forest fire spot pond goose fleeing across str...  \n",
       "3               apocalypse lighting spokane wildfire  \n",
       "4                 typhoon soudelor kill china taiwan  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizar: Pad_sequence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "count_treino_tfidf = tfidf_vectorizer.fit_transform(train_df['text'])\n",
    "count_teste_tfidf = tfidf_vectorizer.transform(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features=5000\n",
    "tokenizer=Tokenizer(num_words=max_features,split=' ')\n",
    "l=50\n",
    "tokenizer.fit_on_texts(train_df['text'])\n",
    "tokenizer.fit_on_texts(test_df['text'])\n",
    "X_train = tokenizer.texts_to_sequences(train_df['text'])\n",
    "X_test = tokenizer.texts_to_sequences(test_df['text'])\n",
    "X_test = pad_sequences(X_test, maxlen =l)\n",
    "X_train = pad_sequences(X_train, maxlen =l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 50)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 50)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 50, 100)           500000    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 50, 100)           0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 50, 100)           80400     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 50, 100)           0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 660,901\n",
      "Trainable params: 660,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 100\n",
    "lstm_out = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_dim,input_length = X_train.shape[1]))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, return_sequences=True,recurrent_dropout=0.4))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(lstm_out,dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "adam = optimizers.Adam(learning_rate=2e-3)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer=adam ,metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "191/191 [==============================] - 66s 315ms/step - loss: 0.5236 - accuracy: 0.7452 - val_loss: 0.4590 - val_accuracy: 0.7991\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 55s 287ms/step - loss: 0.3610 - accuracy: 0.8465 - val_loss: 0.4960 - val_accuracy: 0.7590\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 54s 285ms/step - loss: 0.2909 - accuracy: 0.8865 - val_loss: 0.5336 - val_accuracy: 0.7505\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 54s 284ms/step - loss: 0.2412 - accuracy: 0.9072 - val_loss: 0.6261 - val_accuracy: 0.7538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b0000a0880>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, epochs = 10,validation_split = 0.2 ,callbacks=[es_callback], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 6s 49ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission[\"target\"]=y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/238 [==============================] - 12s 48ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy = round(metrics.accuracy_score(y_train,model.predict(X_train).round())*100)\n",
    "train_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submissão "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (tags/v3.9.6:db3ff76, Jun 28 2021, 15:26:21) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97df6f2fb7f9c55379e2d2444043f8d5f157c223a696fe5032f4316ff3fcd6e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
